{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkNFXr6/J8Xdzcqv5sJhig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suryanshagrawal19/Proof_Generation/blob/main/transformer%20(greedy_approach).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daG7gFxl3SX6",
        "outputId": "5adc7ebf-1e77-42cb-d74e-825def60cb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 100000 examples from combined_dataset.parquet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/28: 100%|██████████| 250/250 [01:59<00:00,  2.10it/s, loss=3.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28 completed. Avg Loss: 4.9796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/28 completed. Avg Loss: 2.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/28: 100%|██████████| 250/250 [01:59<00:00,  2.10it/s, loss=0.791]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/28 completed. Avg Loss: 1.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/28: 100%|██████████| 250/250 [01:58<00:00,  2.11it/s, loss=0.748]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/28 completed. Avg Loss: 0.6626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=0.527]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/28 completed. Avg Loss: 0.4761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/28: 100%|██████████| 250/250 [01:57<00:00,  2.12it/s, loss=0.202]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/28 completed. Avg Loss: 0.3593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=0.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/28 completed. Avg Loss: 0.2875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/28: 100%|██████████| 250/250 [01:56<00:00,  2.15it/s, loss=0.315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/28 completed. Avg Loss: 0.2290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/28: 100%|██████████| 250/250 [01:59<00:00,  2.09it/s, loss=0.148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/28 completed. Avg Loss: 0.1857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=0.254]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/28 completed. Avg Loss: 0.1607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/28: 100%|██████████| 250/250 [01:58<00:00,  2.11it/s, loss=0.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/28 completed. Avg Loss: 0.1336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/28: 100%|██████████| 250/250 [01:56<00:00,  2.14it/s, loss=0.0758]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/28 completed. Avg Loss: 0.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/28: 100%|██████████| 250/250 [01:55<00:00,  2.16it/s, loss=0.178]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/28 completed. Avg Loss: 0.1010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/28: 100%|██████████| 250/250 [01:56<00:00,  2.14it/s, loss=0.0645]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/28 completed. Avg Loss: 0.0864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/28: 100%|██████████| 250/250 [01:56<00:00,  2.14it/s, loss=0.0994]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/28 completed. Avg Loss: 0.0763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/28: 100%|██████████| 250/250 [01:57<00:00,  2.12it/s, loss=0.0961]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/28 completed. Avg Loss: 0.0675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/28: 100%|██████████| 250/250 [01:56<00:00,  2.14it/s, loss=0.0424]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/28 completed. Avg Loss: 0.0610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/28: 100%|██████████| 250/250 [01:58<00:00,  2.12it/s, loss=0.0478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/28 completed. Avg Loss: 0.0540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/28: 100%|██████████| 250/250 [01:56<00:00,  2.15it/s, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/28 completed. Avg Loss: 0.0490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/28: 100%|██████████| 250/250 [01:56<00:00,  2.14it/s, loss=0.0365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/28 completed. Avg Loss: 0.0446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/28: 100%|██████████| 250/250 [01:55<00:00,  2.16it/s, loss=0.011]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/28 completed. Avg Loss: 0.0408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/28: 100%|██████████| 250/250 [01:57<00:00,  2.12it/s, loss=0.0442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/28 completed. Avg Loss: 0.0366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/28: 100%|██████████| 250/250 [01:56<00:00,  2.15it/s, loss=0.0599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/28 completed. Avg Loss: 0.0331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=0.0468]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/28 completed. Avg Loss: 0.0297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/28: 100%|██████████| 250/250 [01:58<00:00,  2.11it/s, loss=0.0103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/28 completed. Avg Loss: 0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/28: 100%|██████████| 250/250 [01:57<00:00,  2.14it/s, loss=0.0472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/28 completed. Avg Loss: 0.0254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=0.0293]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/28 completed. Avg Loss: 0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/28: 100%|██████████| 250/250 [01:57<00:00,  2.13it/s, loss=0.00993]\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/28 completed. Avg Loss: 0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 3it [00:00, 14.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma meet _ le x y z : z ≤ x → z ≤ y → z ≤ x y.\n",
            "Actual Proof:    lemma meet _ le x y z : z ≤ x → z ≤ y → z ≤ x y.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma meet _ sl _ mor _ reflecting ` {! injective f } : orderreflecting f.\n",
            "Actual Proof:    lemma meet _ sl _ mor _ reflecting ` {! injective f } : orderreflecting f.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma lt _ flip x y : x < y → ¬y < x.\n",
            "Actual Proof:    lemma lt _ flip x y : x < y → ¬y < x.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma not _ lt _ apart _ lt _ flip x y : ¬x < y → x y → y < x.\n",
            "Actual Proof:    lemma not _ lt _ apart _ lt _ flip x y : ¬x < y → x y → y < x.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 5it [00:00, 14.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma le _ not _ lt _ flip x y : y ≤ x → ¬x < y.\n",
            "Actual Proof:    lemma le _ not _ lt _ flip x y : y ≤ x → ¬x < y.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma not _ le _ lt _ flip ` {! lapart a } ` { x y, decision ( x = y ) } x y : ¬y ≤ x → x < y.\n",
            "Actual Proof:    lemma not _ le _ lt _ flip ` {! trivialapart a } ` { x y, decision ( x = y ) } x y : ¬y ≤ x → x < y.\n",
            "Match Accuracy:  97.06%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 9it [00:03,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma compose _ le x y z : 0 ≤ z → y = x + z → x ≤ y.\n",
            "Actual Proof:    lemma compose _ le x y z : 0 ≤ z → y = x + z → x ≤ y.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma nonneg _ nonpos _ mult x y : 0 ≤ x → y ≤ 0 → x * y ≤ 0.\n",
            "Actual Proof:    lemma nonneg _ nonpos _ mult x y : 0 ≤ x → y ≤ 0 → x * y ≤ 0.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma decompose _ lt { x y } : x < y → z, 0 < z ∧ y = x + z.\n",
            "Actual Proof:    lemma decompose _ lt { x y } : x < y → z, 0 < z ∧ y = x + z.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 11it [00:04,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma pos _ neg _ mult x y : 0 < x → y < 0 → x * y < 0.\n",
            "Actual Proof:    lemma pos _ neg _ mult x y : 0 < x → y < 0 → x * y < 0.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma lt _ 1 _ 4 : 1 < 4.\n",
            "Actual Proof:    lemma lt _ 1 _ 4 : 1 < 4.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma pos _ plus _ le _ lt _ compat _ r x y z : 0 < z → x ≤ y → x < y + z.\n",
            "Actual Proof:    lemma pos _ plus _ le _ lt _ compat _ r x y z : 0 < z → x ≤ y → x < y + z.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 13it [00:04,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma le _ 2 _ 3 : 2 ≤ 3.\n",
            "Actual Proof:    lemma le _ 2 _ 3 : 2 ≤ 3.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma projected _ srorder ` { semiring r2 } ` { r2le : le r2 } ( f : r2 → r1 ) ` {! semiring _ morphism f } ` {! injective f } : ( x y, x ≤ y ↔ f x ≤ f y ) → ( x y : r2, x ≤ y → z, y = x + z ) → semiringorder r2le.\n",
            "Actual Proof:    lemma projected _ srorder ` { semiring r2 } ` { r2le : le r2 } ( f : r2 → r1 ) ` {! semiring _ morphism f } ` {! injective f } : ( x y, x ≤ y ↔ f x ≤ f y ) → ( x y : r2, x ≤ y → z, y = x + z ) → semiringorder r2le.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 16it [00:04,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma preserves _ lt _ 1 ` {! strictlyorderpreserving f } x : x < 1 → f x < 1.\n",
            "Actual Proof:    lemma preserves _ lt _ 1 ` {! strictlyorderpreserving f } x : x < 1 → f x < 1.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma between _ to _ ring n : - f n ≤ f n.\n",
            "Actual Proof:    lemma between _ to _ ring n : - f n ≤ f n.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 17it [00:04,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma lt _ iff _ plus _ 1 _ le x y : x < y ↔ x + 1 ≤ y.\n",
            "Actual Proof:    lemma lt _ iff _ plus _ 1 _ le x y : x < y ↔ x + 1 ≤ y.\n",
            "Match Accuracy:  100.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma un mu a ( r : relation a ) ( x y : a ) r ' ( e : r r x a r ' y ) : r x y.\n",
            "Actual Proof:    lemma unjm a ( r : relation a ) ( x y : a ) r ' ( e : r r x a r ' y ) : r x y.\n",
            "Match Accuracy:  6.25%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 20it [00:05,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma bool _ fact _ rel _ true ` ( r : horne a ) { dec : x y, decision ( r x y ) } : x y, bool _ fact _ rel r x y ≡ true ↔ r x y.\n",
            "Actual Proof:    lemma bool _ decide _ rel _ true ` ( r : relation a ) { dec : x y, decision ( r x y ) } : x y, bool _ decide _ rel r x y ≡ true ↔ r x y.\n",
            "Match Accuracy:  93.18%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma quote _ equality { v } { v : vars v } { v ' } { v ' : vars v ' } ( l r : ) ` {! quote novars l v } ` {! quote v r v ' } : let heap : = ( merge v v ' ) in eval heap ( map _ var : quote ) = eval heap quote → l = r.\n",
            "Actual Proof:    lemma quote _ equality { v } { v : vars v } { v ' } { v ' : vars v ' } ( l r : value ) ` {! quote novars l v } ` {! quote v r v ' } : let heap : = ( merge v v ' ) in eval heap ( map _ var monkey quote ) = eval heap quote → l = r.\n",
            "Match Accuracy:  40.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 22it [00:05,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: remark subsets _ 1 : forall b : t, subset b app _ 1 - > cardinal b = 1 - > { b [ = ] 1 + + empty } + { b [ = ] 2 + + empty } + { b [ = ] 3 + + empty }.\n",
            "Actual Proof:    remark subsets _ 1 : forall b : t, subset b town _ 1 - > cardinal b = 1 - > { b [ = ] 1 + + empty } + { b [ = ] 2 + + empty } + { b [ = ] 3 + + empty }.\n",
            "Match Accuracy:  98.15%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: remark₁ _ sym : m n, m n - n m.\n",
            "Actual Proof:    remark familiarity₁ _ sym : m n, m n ⇒ n m.\n",
            "Match Accuracy:  0.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 23it [00:05,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: remark ac %tance _ 2 : b, b le * _ 2 - | b | = 2 -, d mk ( n _ 2 \\ b ) ∧ ( b, b mkb - d b ).\n",
            "Actual Proof:    remark acquintance _ 2 : b, b⊆town _ 2 ⇒ | b | = 2 ⇒, d∈ ( town _ 2 \\ b ) ∧ ( b, b∈b ⇒ d b ).\n",
            "Match Accuracy:  3.12%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 25it [00:06,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma neq _ lp _ _ beta _ : _ aux2 : forall ( =xp1 =xp2 : z - > z ), valid _ exp =xp1 - > valid _ exp =xp2 - > forall (phi1phi2 : z - > bool ), forall x, 0 < x - > ( =xp2 ( x ) < =xp1 ( x ) ) % z - > lpp beta =xp1 x < x < = lpp beta =xp1 x + / 2 * ]p beta =xp2 x - > round _ round _ eq beta =xp1 =xp2phi1phi2 x.\n",
            "Actual Proof:    lemma neq _ midpoint _ beta _ odd _ aux2 : forall ( fexp1 fexp2 : z - > z ), valid _ exp fexp1 - > valid _ exp fexp2 - > forall ( choice1 choice2 : z - > bool ), forall x, 0 < x - > ( fexp2 ( mag x ) < fexp1 ( mag x ) ) % z - > midp beta fexp1 x < x < = midp beta fexp1 x + / 2 * ulp beta fexp2 x - > round _ round _ eq beta fexp1 fexp2 choice1 choice2 x.\n",
            "Match Accuracy:  4.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: theorem round _ round _ mult _ beta _ : _ht : forallphi1phi2, ( branchingn ' < = branchingn ) % z - > ( prec < = prec ' ) % z - > forall x y,ht _1 beta branchingn prec x - >ht _1 beta branchingn prec y - > round _ round _ eq beta (ht _ exp branchingn prec ) (ht _ exp branchingn ' prec ' )phi1phi2 ( x * y ).\n",
            "Actual Proof:    theorem round _ round _ mult _ beta _ odd _ flt : forall choice1 choice2, ( emin ' < = emin ) % z - > ( prec < = prec ' ) % z - > forall x y, flt _ format beta emin prec x - > flt _ format beta emin prec y - > round _ round _ eq beta ( flt _ exp emin prec ) ( flt _ exp emin ' prec ' ) choice1 choice2 ( x * y ).\n",
            "Match Accuracy:  12.50%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 26it [00:06,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: theorem round _ round _ plus _ beta _ : _ _x : forall i1 i2, ( prec < = prec ' ) % z - > forall x y, _x _1 beta prec x - > _x _1 beta prec y - > round _ round _ eq beta ( _x _ exp prec ) ( _x _ exp prec ' ) i1 i2 ( x + y ).\n",
            "Actual Proof:    theorem round _ round _ plus _ beta _ odd _ flx : forall choice1 choice2, ( prec < = prec ' ) % z - > forall x y, flx _ format beta prec x - > flx _ format beta prec y - > round _ round _ eq beta ( flx _ exp prec ) ( flx _ exp prec ' ) choice1 choice2 ( x + y ).\n",
            "Match Accuracy:  38.89%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 28it [00:06,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: theorem round _ round _ sqrt _ beta _ : _ _x : forall i1 i2, ( prec < = prec ' ) % z - > forall x, _x _1 beta prec x - > round _ round _ eq beta ( _x _ exp prec ) ( _x _ exp prec ' ) i1 i2 ( sqrt x ).\n",
            "Actual Proof:    theorem round _ round _ sqrt _ beta _ odd _ flx : forall choice1 choice2, ( prec < = prec ' ) % z - > forall x, flx _ format beta prec x - > round _ round _ eq beta ( flx _ exp prec ) ( flx _ exp prec ' ) choice1 choice2 ( sqrt x ).\n",
            "Match Accuracy:  40.32%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma round _ round _ div _ beta _ : _ st : forallalxp1alxp2 : z - > z, valid _ expalxp1 - > valid _ expalxp2 - > ( forall ex, (alxp2 ex < =alxp1 ex ) % z ) - > forall x y, y < > 0 - > _ _1 betaalxp1 x - > _ _1 betaalxp1 y - > round betaalxp1 z hma ( round betaalxp2 z hma ( x / y ) ) = round betaalxp1 z hma ( x / y ).\n",
            "Actual Proof:    lemma round _ round _ div _ beta _ odd _ rna : forall fexp1 fexp2 : z - > z, valid _ exp fexp1 - > valid _ exp fexp2 - > ( forall ex, ( fexp2 ex < = fexp1 ex ) % z ) - > forall x y, y < > 0 - > generic _ format beta fexp1 x - > generic _ format beta fexp1 y - > round beta fexp1 znearesta ( round beta fexp2 znearesta ( x / y ) ) = round beta fexp1 znearesta ( x / y ).\n",
            "Match Accuracy:  14.14%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 29it [00:07,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma tnd _ minus : forall m m u1 v1 b1 b1 v v2 b2 b2, tnd m m u1 v1 b1 b1 - > tnd m m v v2 b2 b2 - > tnd m m ( u1 - v ) ( v1 - v2 ) ( fpl x b1 b2 ) ( fpl x b1 b2 ).\n",
            "Actual Proof:    lemma hombnd _ minus : forall m m u1 v1 b1 b1 u2 v2 b2 b2, hombnd m m u1 v1 b1 b1 - > hombnd m m u2 v2 b2 b2 - > hombnd m m ( u1 - u2 ) ( v1 - v2 ) ( fplus b1 b2 ) ( fplus b1 b2 ).\n",
            "Match Accuracy:  71.93%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 31it [00:07,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma t bnd _ mul : forall { m m1 u1 v1 b1 b1 m2 v v2 b2 b2 }, t bnd ' m m1 u1 v1 b1 b1 - > t bnd ' m m2 v v2 b2 b2 - > t bnd ' m ( m1 * m2 ) ( u1 * v ) ( v1 * v2 ) ( mult _fr b1 b1 b2 b2 ) ( fmult b1 b2 ).\n",
            "Actual Proof:    lemma hombnd _ mul : forall { m m1 u1 v1 b1 b1 m2 u2 v2 b2 b2 }, hombnd ' m m1 u1 v1 b1 b1 - > hombnd ' m m2 u2 v2 b2 b2 - > hombnd ' m ( m1 * m2 ) ( u1 * u2 ) ( v1 * v2 ) ( mult _ err b1 b1 b2 b2 ) ( fmult b1 b2 ).\n",
            "Match Accuracy:  4.23%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma i _ le _ l : forall a b c, 0 < a - > b < = c / a - > a * b < = c.\n",
            "Actual Proof:    lemma rdiv _ le _ l : forall a b c, 0 < a - > b < = c / a - > a * b < = c.\n",
            "Match Accuracy:  96.67%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 33it [00:07,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: theorem mult _ correct : forall x y : _ beta, round beta clxp →d ( f2r x * f2r y ) = f2r ( mult x y ).\n",
            "Actual Proof:    theorem mult _ correct : forall x y : float beta, round beta fexp rnd ( f2r x * f2r y ) = f2r ( mult x y ).\n",
            "Match Accuracy:  89.66%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: theorem exp _ correct : forall x : r, _ _1 _dix2 ( _t _ exp ( - f4 ) aux ) x - > -6 < = x < = _ - > _. ( ( _ exp x - exp x ) / exp x ) < = 1 * pow2 ( - 51 ).\n",
            "Actual Proof:    theorem exp _ correct : forall x : r, generic _ format radix2 ( flt _ exp ( - 1074 ) 53 ) x - > - 746 < = x < = 710 - > rabs ( ( cw _ exp x - exp x ) / exp x ) < = 1 * pow2 ( - 51 ).\n",
            "Match Accuracy:  18.33%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 35it [00:08,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma nat _ : 0 < = m.\n",
            "Actual Proof:    lemma mpos : 0 < = m.\n",
            "Match Accuracy:  14.29%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemmafr _ in _ : forall x,fr ( round _ _x x ) x eps.\n",
            "Actual Proof:    lemma err _ init : forall x, err ( round _ flx x ) x eps.\n",
            "Match Accuracy:  12.50%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 37it [00:08,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma m _ correct :fr m e _ m ( _ / 2 * eps + eva * eps * eps ).\n",
            "Actual Proof:    lemma m _ correct : err m e _ m ( 15 / 2 * eps + 26 * eps * eps ).\n",
            "Match Accuracy:  17.39%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma _t _ pos _ is _ pos : forall x, 0 < = x - > 0 < = round _ _t x.\n",
            "Actual Proof:    lemma flt _ pos _ is _ pos : forall x, 0 < = x - > 0 < = round _ flt x.\n",
            "Match Accuracy:  91.67%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 39it [00:08,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma t4 _ nt _ : t4 = c - ( a - b ).\n",
            "Actual Proof:    lemma t4 _ exact _ : t4 = c - ( a - b ).\n",
            "Match Accuracy:  93.33%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemmafr _ mult _ : forall x1 y1 e1 x2 y2 e2,1 x1 - >1 x2 - >fr x1 y1 e1 - >fr x2 y2 e2 - > ( bp ( sn + prec - 1 ) < _. ( round _ annt ( x1 * x2 ) ) ) - >fr ( round _ annt ( x1 * x2 ) ) ( y1 * y2 ) ( eps + ( 1 + eps ) * ( e1 + e2 + e1 * e2 ) ).\n",
            "Actual Proof:    lemma err _ mult _ : forall x1 y1 e1 x2 y2 e2, format x1 - > format x2 - > err x1 y1 e1 - > err x2 y2 e2 - > ( bpow ( emin + prec - 1 ) < rabs ( round _ flt ( x1 * x2 ) ) ) - > err ( round _ flt ( x1 * x2 ) ) ( y1 * y2 ) ( eps + ( 1 + eps ) * ( e1 + e2 + e1 * e2 ) ).\n",
            "Match Accuracy:  5.43%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 41it [00:09,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma delta _ correct _ : / 4 * bp ( z l ( ( ( izr ( sn + prec - 1 ) ) / 2 ) ) < delta - > ( _. ( delta - e _ delta ) < = ( / 4 * eps + fun * eps * eps ) * e _ delta ).\n",
            "Actual Proof:    lemma delta _ correct _ : / 4 * bpow ( zceil ( ( izr ( emin + prec - 1 ) ) / 2 ) ) < delta - > ( rabs ( delta - e _ delta ) < = ( 23 / 4 * eps + 38 * eps * eps ) * e _ delta ).\n",
            "Match Accuracy:  21.67%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma ]p _ sqr _ ]p _ lt : forall u, 0 < u - > ( u < sqrt ( izr ( _dix _ val beta ) ) * bp prove ( beta u - 1 ) ) - > ]p _ flx ( u * u ) + ]p _ flx u * ]p _ flx u / 2 < 2 * u * ]p _ flx u.\n",
            "Actual Proof:    lemma ulp _ sqr _ ulp _ lt : forall u, 0 < u - > ( u < sqrt ( izr ( radix _ val beta ) ) * bpow ( mag beta u - 1 ) ) - > ulp _ flx ( u * u ) + ulp _ flx u * ulp _ flx u / 2 < 2 * u * ulp _ flx u.\n",
            "Match Accuracy:  85.71%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 43it [00:09,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: theorem round _ =x _ sqr _ sqrt _ aux1 _ simpl : ( / 2 * bp ( beta x ) + bp ( 2 + beta x - prec ) < = ( 2 * izr k + 1 ) * x ) - > xk < = z.\n",
            "Actual Proof:    theorem round _ flx _ sqr _ sqrt _ aux1 _ simpl : ( / 2 * bpow ( mag beta x ) + bpow ( 2 + mag beta x - prec ) < = ( 2 * izr k + 1 ) * x ) - > xk < = z.\n",
            "Match Accuracy:  32.08%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: theorem round _ _x _ sqr _ sqrt _ w : forall x,1 x - > ( beta < = 4 ) % z - > round _ _x2 ( sqrt ( round _ _x1 ( x * x ) ) ) = _. x.\n",
            "Actual Proof:    theorem round _ flx _ sqr _ sqrt _ exact : forall x, format x - > ( beta < = 4 ) % z - > round _ flx2 ( sqrt ( round _ flx1 ( x * x ) ) ) = rabs x.\n",
            "Match Accuracy:  26.09%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 45it [00:09,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: theorem sqrt _ sqr : forall x y : r,1 x - > - 1 < = round _ annx1 ( x / round _ annx2 ( r _ sqrt. sqrt ( round _ annx3 ( round _ annx4 ( x * x ) + round _ annx5 ( y * y ) ) ) ) ) < = 1.\n",
            "Actual Proof:    theorem sqrt _ sqr : forall x y : r, format x - > - 1 < = round _ flx1 ( x / round _ flx2 ( r _ sqrt. sqrt ( round _ flx3 ( round _ flx4 ( x * x ) + round _ flx5 ( y * y ) ) ) ) ) < = 1.\n",
            "Match Accuracy:  21.31%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma round _ plus _ small _ id : forall f h,1 f - > ( bp [ ( prec + len ) < = _. f ) - > _. h < = / 4 * ]p _ hct f - > round _ hct ( f + h ) = f.\n",
            "Actual Proof:    lemma round _ plus _ small _ id : forall f h, format f - > ( bpow ( prec + emin ) < = rabs f ) - > rabs h < = / 4 * ulp _ flt f - > round _ flt ( f + h ) = f.\n",
            "Match Accuracy:  75.47%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 47it [00:10,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma avg _set _ no _mma var : ( bp sn ) < = _. a - > av < > 0.\n",
            "Actual Proof:    lemma avg _ naive _ no _ underflow : ( bpow emin ) < = rabs a - > av < > 0.\n",
            "Match Accuracy:  8.70%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma avg _ half _ sub _ between : lein x y < = av < = le _ x y.\n",
            "Actual Proof:    lemma avg _ half _ sub _ between : rmin x y < = av < = rmax x y.\n",
            "Match Accuracy:  80.00%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 49it [00:10,  6.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma avg _ half _ sub _ correct _ aux2 : forall u v,1 u - >1 v - > u < = v - > ( 0 < = u / \\ 0 < = v ) \\ / ( u < = 0 / \\ v < = 0 ) - > _ ( avg _ half _ sub u v - ( ( u + v ) / 2 ) ) < = 3 / 2 * ]p _ flt ( ( u + v ) / 2 ).\n",
            "Actual Proof:    lemma avg _ half _ sub _ correct _ aux2 : forall u v, format u - > format v - > u < = v - > ( 0 < = u / \\ 0 < = v ) \\ / ( u < = 0 / \\ v < = 0 ) - > rabs ( avg _ half _ sub u v - ( ( u + v ) / 2 ) ) < = 3 / 2 * ulp _ flt ( ( u + v ) / 2 ).\n",
            "Match Accuracy:  14.89%\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Proof: lemma ( _ zero : a = 0 - > av = 0.\n",
            "Actual Proof:    lemma average _ zero : a = 0 - > av = 0.\n",
            "Match Accuracy:  92.31%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 50it [00:10,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Proof: lemma round _ ne _ pt _ pos : forall x, ( 0 < x ) % r - >d _ ne _ pt x ( round beta =xp z ye x ).\n",
            "Actual Proof:    lemma round _ ne _ pt _ pos : forall x, ( 0 < x ) % r - > rnd _ ne _ pt x ( round beta fexp zneareste x ).\n",
            "Match Accuracy:  63.64%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Exact Match Accuracy: 32.00%\n",
            "Average BLEU Score:   0.7838\n",
            "Average METEOR Score: 0.8954\n",
            "Average ROUGE Score:  1.7147\n",
            "Average Match Accuracy: 61.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import PreTrainedModel, PretrainedConfig, AutoTokenizer\n",
        "import pandas as pd  # To load the Parquet dataset\n",
        "from tqdm import tqdm  # For progress bar\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "\n",
        "# Helper function: Compute token-level exact match accuracy.\n",
        "def get_match_accuracy(generated: str, actual: str) -> float:\n",
        "    \"\"\"\n",
        "    Computes the percentage of tokens in the actual proof that match the tokens in the generated proof (in order).\n",
        "    Returns a percentage value.\n",
        "    \"\"\"\n",
        "    gen_tokens = generated.split()\n",
        "    actual_tokens = actual.split()\n",
        "    if not actual_tokens:\n",
        "        return 0.0\n",
        "    # Count tokens that match in the same position.\n",
        "    matches = sum(1 for gt, at in zip(gen_tokens, actual_tokens) if gt == at)\n",
        "    return (matches / len(actual_tokens)) * 100\n",
        "\n",
        "# 1. Load Parquet Dataset Function\n",
        "def load_dataset(file_path=\"combined_dataset.parquet\"):\n",
        "    try:\n",
        "        df = pd.read_parquet(file_path)\n",
        "        proof_pairs = list(zip(df[\"Output\"], df[\"Theorem\"]))  # Adjust column names as needed.\n",
        "        print(f\"Loaded {len(proof_pairs)} examples from {file_path}.\")\n",
        "        return proof_pairs\n",
        "    except Exception as e:\n",
        "        print(\"Error loading dataset:\", e)\n",
        "        # Return a small dummy dataset if the file is not found.\n",
        "        return [(\"axiom A -> B\", \"theorem A implies B\"), (\"forall x, P(x)\", \"universal quantifier P(x)\")]\n",
        "\n",
        "# 2. Model & Configuration Classes\n",
        "class ProofTransformerConfig(PretrainedConfig):\n",
        "    def __init__(self, vocab_size=30522, d_model=512, num_layers=8, nhead=8,\n",
        "                 dim_feedforward=4096, dropout=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.nhead = nhead\n",
        "        self.dim_feedforward = dim_feedforward\n",
        "        self.dropout = dropout\n",
        "\n",
        "class ProofTransformer(PreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.token_embedding = nn.Embedding(config.vocab_size, config.d_model)\n",
        "        # Using a fixed maximum sequence length of 1000 for positional encoding.\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, config.d_model))\n",
        "\n",
        "        self.encoder = Transformer(\n",
        "            d_model=config.d_model,\n",
        "            nhead=config.nhead,\n",
        "            num_encoder_layers=config.num_layers,\n",
        "            num_decoder_layers=config.num_layers,\n",
        "            dim_feedforward=config.dim_feedforward,\n",
        "            dropout=config.dropout,\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(config.d_model, config.vocab_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, decoder_input_ids):\n",
        "        src = self.token_embedding(input_ids) + self.positional_encoding[:, :input_ids.shape[1], :]\n",
        "        tgt = self.token_embedding(decoder_input_ids) + self.positional_encoding[:, :decoder_input_ids.shape[1], :]\n",
        "\n",
        "        # Transformer expects input as [sequence_length, batch_size, d_model]\n",
        "        src = src.transpose(0, 1)\n",
        "        tgt = tgt.transpose(0, 1)\n",
        "\n",
        "        output = self.encoder(src, tgt)\n",
        "\n",
        "        output = output.transpose(0, 1)\n",
        "        logits = self.lm_head(output)\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "# 3. Dataset, DataLoader, Tokenizer\n",
        "class ProofDataset(Dataset):\n",
        "    def __init__(self, tokenizer, proof_pairs, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = proof_pairs\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text, target_text = self.data[idx]\n",
        "        input_ids = self.tokenizer.encode(\n",
        "            input_text, add_special_tokens=True,\n",
        "            return_tensors=\"pt\", max_length=self.max_length, truncation=True\n",
        "        ).squeeze(0)\n",
        "        target_ids = self.tokenizer.encode(\n",
        "            target_text, add_special_tokens=True,\n",
        "            return_tensors=\"pt\", max_length=self.max_length, truncation=True\n",
        "        ).squeeze(0)\n",
        "        # Return as tuple of dictionaries (each representing one side of the pair)\n",
        "        return {\"input_ids\": input_ids}, {\"input_ids\": target_ids}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Since __getitem__ returns a tuple (input_dict, target_dict), we unpack here:\n",
        "    inputs, targets = zip(*batch)\n",
        "    input_ids = [item[\"input_ids\"] for item in inputs]\n",
        "    target_ids = [item[\"input_ids\"] for item in targets]\n",
        "    input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
        "    target_ids = nn.utils.rnn.pad_sequence(target_ids, batch_first=True, padding_value=0)\n",
        "    return {\"input_ids\": input_ids, \"target_ids\": target_ids}\n",
        "\n",
        "# 4. Greedy Decoding Function\n",
        "def greedy_decode(logits):\n",
        "    # Select the token with the highest probability at each time step.\n",
        "    token_ids = torch.argmax(logits, dim=-1)\n",
        "    # Return the tokens for the first sequence in the batch.\n",
        "    return token_ids[0].cpu().tolist()\n",
        "\n",
        "# 5. Evaluation Function with Additional Metrics (ROUGE, METEOR, and Match Accuracy)\n",
        "def evaluate_accuracy(model, dataloader, tokenizer, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    bleu_scores = []\n",
        "    meteor_scores = []\n",
        "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scorer_values = []\n",
        "    match_accuracies = []  # List to store match accuracies for each proof\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in tqdm(enumerate(dataloader), desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            target_ids = batch[\"target_ids\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, decoder_input_ids=target_ids)\n",
        "            logits = outputs[\"logits\"]\n",
        "\n",
        "            # Use greedy decoding for evaluation on the first example of the batch.\n",
        "            decoded_tokens = greedy_decode(logits)\n",
        "            generated_proof = tokenizer.decode(decoded_tokens, skip_special_tokens=True)\n",
        "            actual_proof = tokenizer.decode(target_ids[0], skip_special_tokens=True)\n",
        "\n",
        "            # Print proofs and calculate match accuracy.\n",
        "            print(f\"Generated Proof: {generated_proof}\")\n",
        "            print(f\"Actual Proof:    {actual_proof}\")\n",
        "            match_acc = get_match_accuracy(generated_proof, actual_proof)\n",
        "            match_accuracies.append(match_acc)\n",
        "            print(f\"Match Accuracy:  {match_acc:.2f}%\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            # Exact match evaluation (full string exact match).\n",
        "            if generated_proof == actual_proof:\n",
        "                correct += 1\n",
        "\n",
        "            # Compute BLEU score for semantic similarity.\n",
        "            bleu_score = sentence_bleu([actual_proof.split()], generated_proof.split())\n",
        "            bleu_scores.append(bleu_score)\n",
        "\n",
        "            # Compute METEOR score (using tokenized strings).\n",
        "            meteor_scores.append(meteor_score([actual_proof.split()], generated_proof.split()))\n",
        "\n",
        "            # Compute ROUGE score (sum of f-measures from rouge1 and rougeL).\n",
        "            rouge_score_dict = rouge_scorer_obj.score(actual_proof, generated_proof)\n",
        "            rouge_total = rouge_score_dict['rouge1'].fmeasure + rouge_score_dict['rougeL'].fmeasure\n",
        "            rouge_scorer_values.append(rouge_total)\n",
        "\n",
        "            total += 1\n",
        "\n",
        "    if total == 0:\n",
        "        print(\"No examples evaluated in the test set. Check your test data slice.\")\n",
        "        return\n",
        "\n",
        "    accuracy = (correct / total * 100) if total > 0 else 0\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
        "    avg_meteor = sum(meteor_scores) / len(meteor_scores) if meteor_scores else 0\n",
        "    avg_rouge = sum(rouge_scorer_values) / len(rouge_scorer_values) if rouge_scorer_values else 0\n",
        "    avg_match_acc = sum(match_accuracies) / len(match_accuracies) if match_accuracies else 0\n",
        "\n",
        "    print(f\"\\nExact Match Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Average BLEU Score:   {avg_bleu:.4f}\")\n",
        "    print(f\"Average METEOR Score: {avg_meteor:.4f}\")\n",
        "    print(f\"Average ROUGE Score:  {avg_rouge:.4f}\")\n",
        "    print(f\"Average Match Accuracy: {avg_match_acc:.2f}%\")\n",
        "\n",
        "# 6. Initialize Tokenizer, Model, Optimizer, and set Device\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "config = ProofTransformerConfig()\n",
        "model = ProofTransformer(config)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
        "epochs = 28\n",
        "reward_weight = 0.1\n",
        "\n",
        "# Load dataset from Parquet file\n",
        "proof_data = load_dataset(\"combined_dataset.parquet\")\n",
        "\n",
        "# 7. Split dataset into training and testing examples.\n",
        "# Correcting the slice for test data: using indices 2000 to 2400 for a 400-example test set.\n",
        "train_data = proof_data[:2000]\n",
        "test_data = proof_data[2000:2400]\n",
        "\n",
        "train_dataset = ProofDataset(tokenizer, train_data, max_length=512)\n",
        "test_dataset = ProofDataset(tokenizer, test_data, max_length=512)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# 8. Training Loop with Gradient Accumulation\n",
        "accumulation_steps = 4  # Accumulate gradients over 4 steps (simulates a larger effective batch size)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch+1}/{epochs}\", total=len(train_dataloader))\n",
        "\n",
        "    # Zero gradients outside the loop to begin accumulation.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, batch in progress_bar:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        target_ids = batch[\"target_ids\"].to(device)\n",
        "\n",
        "        # Forward pass.\n",
        "        outputs = model(input_ids=input_ids, decoder_input_ids=target_ids)\n",
        "        logits = outputs[\"logits\"]\n",
        "\n",
        "        # Compute cross-entropy loss. Flatten the tensors so that we can compare predictions with targets.\n",
        "        ce_loss = loss_fn(logits.view(-1, config.vocab_size), target_ids.view(-1))\n",
        "        ce_loss.backward()\n",
        "\n",
        "        # Gradient accumulation step.\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += ce_loss.item()\n",
        "        progress_bar.set_postfix({\"loss\": ce_loss.item()})\n",
        "\n",
        "    # If there are leftover gradients, update once more.\n",
        "    if (batch_idx + 1) % accumulation_steps != 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_loss = running_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} completed. Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# 9. Evaluate the model on the test set\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "evaluate_accuracy(model, test_dataloader, tokenizer, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers rouge_score nltk tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsANrOOtSvFN",
        "outputId": "9968bed0-76ae-4abf-9877-85362b2c97b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=13ca2d165d7f98a2754e30fcdc556f09cdba1a15f8f5903e3b23cfd4a7663fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "q4JC4iouW_LH",
        "outputId": "526fa7b9-380b-4e70-d904-18c0c5178dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c4737d29-c7ee-417f-9ac3-2dba6f87142d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c4737d29-c7ee-417f-9ac3-2dba6f87142d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving combined_dataset.parquet to combined_dataset.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install coq -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbpZa-DTWqvn",
        "outputId": "a6a86672-2a5e-4755-8aae-91d55e6df6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ledit libcoq-core-ocaml libcoq-stdlib libfindlib-ocaml libfindlib-ocaml-dev\n",
            "  libzarith-ocaml ocaml ocaml-base ocaml-compiler-libs ocaml-findlib\n",
            "  ocaml-interp ocaml-man ocaml-nox\n",
            "Suggested packages:\n",
            "  coqide | proofgeneral libcoq-core-ocaml-dev why coq-doc ocaml-doc\n",
            "  elpa-tuareg camlp4\n",
            "The following NEW packages will be installed:\n",
            "  coq ledit libcoq-core-ocaml libcoq-stdlib libfindlib-ocaml\n",
            "  libfindlib-ocaml-dev libzarith-ocaml ocaml ocaml-base ocaml-compiler-libs\n",
            "  ocaml-findlib ocaml-interp ocaml-man ocaml-nox\n",
            "0 upgraded, 14 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 281 MB of archives.\n",
            "After this operation, 986 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcoq-stdlib amd64 8.15.0+dfsg-2 [24.7 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml-base amd64 4.13.1-3ubuntu1 [589 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzarith-ocaml amd64 1.12-1build1 [60.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcoq-core-ocaml amd64 8.15.0+dfsg-2 [27.1 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml-compiler-libs amd64 4.13.1-3ubuntu1 [36.2 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml-interp amd64 4.13.1-3ubuntu1 [7,488 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml amd64 4.13.1-3ubuntu1 [87.7 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml-nox all 4.13.1-3ubuntu1 [3,082 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfindlib-ocaml amd64 1.9.1-1build2 [222 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml-findlib amd64 1.9.1-1build2 [559 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 coq amd64 8.15.0+dfsg-2 [95.4 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ledit all 2.04-6build2 [59.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfindlib-ocaml-dev amd64 1.9.1-1build2 [172 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocaml-man all 4.13.1-3ubuntu1 [519 kB]\n",
            "Fetched 281 MB in 12s (24.1 MB/s)\n",
            "Selecting previously unselected package libcoq-stdlib.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libcoq-stdlib_8.15.0+dfsg-2_amd64.deb ...\n",
            "Unpacking libcoq-stdlib (8.15.0+dfsg-2) ...\n",
            "Selecting previously unselected package ocaml-base.\n",
            "Preparing to unpack .../01-ocaml-base_4.13.1-3ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-base (4.13.1-3ubuntu1) ...\n",
            "Selecting previously unselected package libzarith-ocaml.\n",
            "Preparing to unpack .../02-libzarith-ocaml_1.12-1build1_amd64.deb ...\n",
            "Unpacking libzarith-ocaml (1.12-1build1) ...\n",
            "Selecting previously unselected package libcoq-core-ocaml.\n",
            "Preparing to unpack .../03-libcoq-core-ocaml_8.15.0+dfsg-2_amd64.deb ...\n",
            "Unpacking libcoq-core-ocaml (8.15.0+dfsg-2) ...\n",
            "Selecting previously unselected package ocaml-compiler-libs.\n",
            "Preparing to unpack .../04-ocaml-compiler-libs_4.13.1-3ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-compiler-libs (4.13.1-3ubuntu1) ...\n",
            "Selecting previously unselected package ocaml-interp.\n",
            "Preparing to unpack .../05-ocaml-interp_4.13.1-3ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-interp (4.13.1-3ubuntu1) ...\n",
            "Selecting previously unselected package ocaml.\n",
            "Preparing to unpack .../06-ocaml_4.13.1-3ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml (4.13.1-3ubuntu1) ...\n",
            "Selecting previously unselected package ocaml-nox.\n",
            "Preparing to unpack .../07-ocaml-nox_4.13.1-3ubuntu1_all.deb ...\n",
            "Unpacking ocaml-nox (4.13.1-3ubuntu1) ...\n",
            "Selecting previously unselected package libfindlib-ocaml.\n",
            "Preparing to unpack .../08-libfindlib-ocaml_1.9.1-1build2_amd64.deb ...\n",
            "Unpacking libfindlib-ocaml (1.9.1-1build2) ...\n",
            "Selecting previously unselected package ocaml-findlib.\n",
            "Preparing to unpack .../09-ocaml-findlib_1.9.1-1build2_amd64.deb ...\n",
            "Unpacking ocaml-findlib (1.9.1-1build2) ...\n",
            "Selecting previously unselected package coq.\n",
            "Preparing to unpack .../10-coq_8.15.0+dfsg-2_amd64.deb ...\n",
            "Unpacking coq (8.15.0+dfsg-2) ...\n",
            "Selecting previously unselected package ledit.\n",
            "Preparing to unpack .../11-ledit_2.04-6build2_all.deb ...\n",
            "Unpacking ledit (2.04-6build2) ...\n",
            "Selecting previously unselected package libfindlib-ocaml-dev.\n",
            "Preparing to unpack .../12-libfindlib-ocaml-dev_1.9.1-1build2_amd64.deb ...\n",
            "Unpacking libfindlib-ocaml-dev (1.9.1-1build2) ...\n",
            "Selecting previously unselected package ocaml-man.\n",
            "Preparing to unpack .../13-ocaml-man_4.13.1-3ubuntu1_all.deb ...\n",
            "Unpacking ocaml-man (4.13.1-3ubuntu1) ...\n",
            "Setting up libcoq-stdlib (8.15.0+dfsg-2) ...\n",
            "Setting up ocaml-base (4.13.1-3ubuntu1) ...\n",
            "Setting up ocaml-man (4.13.1-3ubuntu1) ...\n",
            "Setting up libfindlib-ocaml (1.9.1-1build2) ...\n",
            "Setting up libzarith-ocaml (1.12-1build1) ...\n",
            "Setting up ledit (2.04-6build2) ...\n",
            "update-alternatives: using /usr/bin/ledit to provide /usr/bin/readline-editor (readline-editor) in auto mode\n",
            "Setting up ocaml-findlib (1.9.1-1build2) ...\n",
            "Setting up libcoq-core-ocaml (8.15.0+dfsg-2) ...\n",
            "Setting up ocaml-interp (4.13.1-3ubuntu1) ...\n",
            "Setting up ocaml (4.13.1-3ubuntu1) ...\n",
            "Setting up libfindlib-ocaml-dev (1.9.1-1build2) ...\n",
            "Setting up ocaml-nox (4.13.1-3ubuntu1) ...\n",
            "Setting up coq (8.15.0+dfsg-2) ...\n",
            "Setting up ocaml-compiler-libs (4.13.1-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install torch_geometric"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CorVSKoQ3-rY",
        "outputId": "23c458b3-a861-4899-d44d-c2c5ea4a93e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ]
    }
  ]
}